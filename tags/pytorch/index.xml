<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PyTorch on Vignesh Sundararajan</title>
    <link>https://vigneshsundararajan.github.io/tags/pytorch/</link>
    <description>Recent content in PyTorch on Vignesh Sundararajan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://vigneshsundararajan.github.io/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CNN Autoencoder for Image Denoising</title>
      <link>https://vigneshsundararajan.github.io/blog/cnn/</link>
      <pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vigneshsundararajan.github.io/blog/cnn/</guid>
      <description>Dataset used MNIST: http://yann.lecun.com/exdb/mnist/
Data augmentation was performed on this dataset by adding a Gaussian noise with $\mu = 0$ and $\sigma = 0.5$. Test-train splits were then created by concatenating the clean images along with their noisy counterparts.
Model Architecture and Training The autoencoder model designed for this task has two convolutional layers along with max pooling in the encoder, and two transpose convolutional layers in the decoder. Training was done for 10 epochs to reduce the loss to a sufficient level.</description>
    </item>
    
  </channel>
</rss>
