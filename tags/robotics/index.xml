<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Robotics on Vignesh Sundararajan</title>
    <link>https://vigneshsundararajan.github.io/tags/robotics/</link>
    <description>Recent content in Robotics on Vignesh Sundararajan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://vigneshsundararajan.github.io/tags/robotics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My Graduate Research in Urban Air Mobility</title>
      <link>https://vigneshsundararajan.github.io/blog/research/</link>
      <pubDate>Fri, 06 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://vigneshsundararajan.github.io/blog/research/</guid>
      <description>Image Credits : NASA The growth of UAM and the role of autonomy in it The world as a collective is transitioning to a more autonomous future with the advent of intelligent transportation vehicles running on renewable energy. The technological advancements run in parallel with the rapid increase in urban population density and the need for quick and reliable point-to-point travel. The UAM concept highlights the use of Urban Air Taxis, that can take off and land vertically from densely populated areas, and as such need to be highly reliable as the UAM market is projected to grow to roughly 28.</description>
    </item>
    
    <item>
      <title>Ball Tracking and Chasing Robot using ROS and Gazebo</title>
      <link>https://vigneshsundararajan.github.io/blog/autsys/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vigneshsundararajan.github.io/blog/autsys/</guid>
      <description>This project was my first introduction to Perception and learning about the different image processing techniques that I could apply for Object Detection using the minimal computational resources! I explored methods such as Canny Edge Detection, and Image Masking to extract only the object of interest from the RGB camera feed. Once that is done, I calculated the distance to the object by finding it&amp;rsquo;s centroid and position relative to the robot.</description>
    </item>
    
    <item>
      <title>Path Planning using Graph Search Algorithms</title>
      <link>https://vigneshsundararajan.github.io/blog/path-planning/</link>
      <pubDate>Sat, 26 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vigneshsundararajan.github.io/blog/path-planning/</guid>
      <description>The GMapping SLAM module on ROS was used to generate an environment map, which was then converted to a graph data structure. This was done by reading in the .pgm and .yaml files into Python, and then inflating the map with a rectangular kernel, followed by conversion to a graph. T he path planning problem was then solved from the map graph representation
Breadth First Search The breadth first search goes through the nodes in an unweighted graph and keeps a queue of the visited and unvisited nodes.</description>
    </item>
    
    <item>
      <title>Monocular Vision based Navigation of a 4-wheeled Robot</title>
      <link>https://vigneshsundararajan.github.io/blog/monovision-nav/</link>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vigneshsundararajan.github.io/blog/monovision-nav/</guid>
      <description>The vision system consisted of a monocular camera system (5MP 1080p Raspberry Pi Camera module) interfaced with a Raspberry Pi running ROS Noetic on Ubuntu. The DC motors running the wheels and the servo controlling the orientation of the camera were handled by an L293D driver board which was connected to the GPIO pins of the Raspberry Pi First, the camera was calibrated using the camera_calibration ROS package that uses a checkerboard pattern as a target and performs calibration on either a monocular or stereo system.</description>
    </item>
    
    <item>
      <title>Lane Detection using OpenCV</title>
      <link>https://vigneshsundararajan.github.io/blog/lane-detection/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vigneshsundararajan.github.io/blog/lane-detection/</guid>
      <description>Lane detection is an important computer vision problem in the context of autonomous driving. In this project, an image is taken as an input and then a Gaussian Blur filter is applied to it. A Sobel Filter was implemented to obtain the grayscale gradient image followed by Canny Edge detection using Non-Max Suppression and Hysteresis Thresholding to extract edges between a specified threshold. Image masking is then used to extract only the edges that are of interest (eg: we don&amp;rsquo;t need the horizon).</description>
    </item>
    
  </channel>
</rss>
